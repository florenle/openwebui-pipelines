services:
  open-webui:
    #Was: image: ghcr.io/open-webui/open-webui:main
    image: my-open-webui:latest
    container_name: open-webui
    ports:
      - "3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - 'OPENAI_API_BASE_URL=http://pipelines:9099/api/v1'
      - 'OPENAI_API_KEY=0p3n-w3bu!'
      - 'HTTP_TIMEOUT=500'
      - 'SKIP_PROCESSING_MODELS=lfbrain'
    depends_on:
      - pipelines
    restart: always
    networks:
      - backend-net

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    ports:
      - "9099:9099"
    volumes:
      - ./pipelines:/app/pipelines
      - open-webui-data:/app/backend/data:ro
      - /home/florenle/x/dev/openwebui/chats:/home/florenle/x/dev/openwebui/chats
    environment:
      WATCH: "True"
      GUNICORN_TIMEOUT: "500"
    restart: always
    networks:
      - backend-net

  lfbrain-orchestrator:
    build: ./lfbrain-orchestrator
    container_name: lfbrain-orchestrator
    ports:
      - "8081:8081"
    restart: unless-stopped
    networks:
      - backend-net

networks:
  backend-net:
    driver: bridge

volumes:
  open-webui-data: